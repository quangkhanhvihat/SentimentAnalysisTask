{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_LSTM_baomoiEmb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRBM76cT_9uK",
        "outputId": "66cd0992-018f-40ce-cc81-ee16dcb0d418"
      },
      "source": [
        "!git clone https://github.com/ntienhuy/MultiChannel"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MultiChannel' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxYELusCaJ4R",
        "outputId": "4bf54a7e-8ab4-48e4-e31f-3c9c494aa8ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4T96wr4uwAv"
      },
      "source": [
        "import torch \n",
        "import numpy as np \n",
        "import re \n",
        "MAX_SEQ_LEN = 100\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 400"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZyfxpZa3dPZ"
      },
      "source": [
        "# Ham xu ly chuỗi sai dấu\n",
        "# ví dụ:  'Nhe ̣ nha ̀ ng sâu lă ́ ng nhưng cu ̃ ng triê ́ t ly ́ va ̀ tinh tê ́ .'\n",
        "def chuan_hoa_dau(s):\n",
        "    dau_nang_sai = ' ̣ '\n",
        "    dau_nang_dung = dau_nang_sai[1]\n",
        "    dau_huyen_sai = ' ̀ '\n",
        "    dau_huyen_dung = dau_huyen_sai[1]\n",
        "    dau_sac_sai = ' ́ '\n",
        "    dau_sac_dung = dau_sac_sai[1]\n",
        "    dau_nga_sai = ' ̃ '\n",
        "    dau_nga_dung = dau_nga_sai[1]\n",
        "    dau_hoi_sai = ' ̉ '\n",
        "    dau_hoi_dung = dau_hoi_sai[1]\n",
        "    dau_cau = {dau_nang_sai : dau_nang_dung,\n",
        "           dau_huyen_sai : dau_huyen_dung,\n",
        "           dau_nga_sai : dau_nga_dung,\n",
        "           dau_sac_sai : dau_sac_dung,\n",
        "           dau_hoi_sai : dau_hoi_dung}\n",
        "    nguyen_am = 'aáàạảãăắằằẳẵâấầậẩẫeéèẻèẽêếềểễệiỉíìĩịoóòỏõọôốồộổỗơớờởỡợuúùụủũưứừựửữyýỳỷỹỵ'\n",
        "\n",
        "    for k, v in dau_cau.items():\n",
        "        while(s.find(k) >= 0):\n",
        "            pos = s.find(k)\n",
        "            s1 = s[pos+3:]\n",
        "            # s2 là những ký tự phía sau dấu câu sai\n",
        "            s2 = s1[:s1.find(' ')]\n",
        "            if len(s2) == 2:\n",
        "                #phía sau là môt từ\n",
        "                if (nguyen_am.find(s2[0])>=0) | (nguyen_am.find(s2[1])>=0):\n",
        "                    s=s.replace(k,v + ' ',1)\n",
        "                #phia sau k phai 1 tu\n",
        "                else: \n",
        "                    s=s.replace(k,v,1)\n",
        "            #phia sau la mot tu\n",
        "            elif len(s2) > 2:\n",
        "                s=s.replace(k,v + ' ',1)\n",
        "            #phia sau chi co 1 ky tu va no la 1 tu dac biet ngan\n",
        "            elif 'áàạéèẻèêếềiíịoóòỏôốồơớờởợuúùụủũưứừựyýỳỵ'.find(s)>0:\n",
        "                s=s.replace(k,v + ' ',1)\n",
        "            else:\n",
        "                s=s.replace(k,v,1)\n",
        "    return s\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGb4uUCgOaxj",
        "outputId": "87bbc756-06b2-447d-fd56-c35af8b894f2"
      },
      "source": [
        "!gdown --id 1TzXkIicD3MsI6ciKnsDfSX4vFmYqd3LV\n",
        "#download teencode.txt"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TzXkIicD3MsI6ciKnsDfSX4vFmYqd3LV\n",
            "To: /content/teencode.txt\n",
            "\r  0% 0.00/5.66k [00:00<?, ?B/s]\r100% 5.66k/5.66k [00:00<00:00, 5.12MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSCpR2jNzAZC"
      },
      "source": [
        "f = open('/content/teencode.txt','r', encoding='UTF-8')\n",
        "teencode_dict = {}\n",
        "for aline in f.readlines():\n",
        "    aline = aline.split()\n",
        "    teencode_dict[aline[0]] = ' '.join(aline[1:])\n",
        "# teencode_dict"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sjSawvRBEWp"
      },
      "source": [
        "def load_data(folder_id):\n",
        "    train_data = []\n",
        "    train_labels = []    \n",
        "    test_data = []\n",
        "    test_labels = []\n",
        "    for label in range(3):\n",
        "\n",
        "        # read train data\n",
        "        path = '/content/MultiChannel/data/VS/Data_Token/Fold_{}/train_nhan_{}.txt'.format(str(folder_id),str(label))\n",
        "        f = open(path, \"r\",encoding='utf-8-sig')\n",
        "        regex = re.compile('[-:()\\\",.!?=`~/+&$%^*#]')\n",
        "        text = []\n",
        "        for aline in f.readlines():\n",
        "            aline = chuan_hoa_dau(aline)\n",
        "            aline = aline.lower()\n",
        "            aline = regex.sub('', aline).strip()\n",
        "            aline = re.sub(' +',' ',aline)\n",
        "            for k,v in teencode_dict.items():\n",
        "                aline.replace(k,v)\n",
        "            if len(aline.split())==0:\n",
        "                continue\n",
        "            text.append(aline)\n",
        "        train_labels += [label]*len(text)\n",
        "        print('label: {}, len: {}'.format(label, len(text)))\n",
        "        train_data +=text\n",
        "        f.close()\n",
        "\n",
        "        # read test data\n",
        "        path = '/content/MultiChannel/data/VS/Data_Token/Fold_{}/test_nhan_{}.txt'.format(str(folder_id),str(label))\n",
        "        f = open(path, \"r\",encoding='utf-8-sig')\n",
        "        regex = re.compile('[-:()\\\",.!?=`~/+&$%^*#]')\n",
        "        text = []\n",
        "        for aline in f.readlines():\n",
        "            aline = chuan_hoa_dau(aline)\n",
        "            aline = aline.lower()\n",
        "            aline = regex.sub('', aline).strip()\n",
        "            aline = re.sub(' +',' ',aline)\n",
        "            for k,v in teencode_dict.items():\n",
        "                aline.replace(k,v)\n",
        "            if len(aline.split())==0:\n",
        "                continue\n",
        "            text.append(aline)\n",
        "        test_labels += [label]*len(text)\n",
        "        test_data += text\n",
        "        f.close()\n",
        "\n",
        "\n",
        "\n",
        "    return train_data, train_labels, test_data, test_labels"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY4WsSePHfvU"
      },
      "source": [
        "folder_id = 1\n",
        "train_data, train_labels, test_data, test_labels = load_data(folder_id=folder_id)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDHnYzh3L_dj",
        "outputId": "0502fbd2-f493-4594-af7b-576bf389ba5f"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(train_labels))\n",
        "print(len(test_data))\n",
        "print(len(test_labels))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29076\n",
            "29076\n",
            "5883\n",
            "5883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ90lNS1MEkv",
        "outputId": "f00db917-5e67-41eb-83cb-22292700bdf8"
      },
      "source": [
        "!pip install pytorch-nlp"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (4.62.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_IZe7cENTyV"
      },
      "source": [
        "from torchnlp.encoders.text import StaticTokenizerEncoder,pad_tensor,stack_and_pad_tensors\n",
        "\n",
        "encoder = StaticTokenizerEncoder(train_data, tokenize=lambda s: s.split())\n",
        "\n",
        "train_encoded = [encoder.encode(aline) for aline in train_data]\n",
        "train_input_len = [len(x) if len(x) < MAX_SEQ_LEN else MAX_SEQ_LEN for x in train_encoded]\n",
        "train_padded = [pad_tensor(x, length=MAX_SEQ_LEN) if len(x)<MAX_SEQ_LEN else x[-MAX_SEQ_LEN:] for x in train_encoded]\n",
        "train_padded = stack_and_pad_tensors(train_padded)\n",
        "\n",
        "test_encoded = [encoder.encode(aline) for aline in test_data]\n",
        "test_input_len = [len(x) if len(x) < MAX_SEQ_LEN else MAX_SEQ_LEN for x in test_encoded]\n",
        "test_padded = [pad_tensor(x, length=MAX_SEQ_LEN) if len(x)<MAX_SEQ_LEN else x[-MAX_SEQ_LEN:] for x in test_encoded]\n",
        "test_padded = stack_and_pad_tensors(test_padded)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_IQHQtQD5oZ",
        "outputId": "6d1bb629-a04b-4d29-b6ec-4d95955132ab"
      },
      "source": [
        "print(max(train_input_len))\n",
        "print(max(test_input_len))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKmi_vEGWRbv"
      },
      "source": [
        "train_labels = torch.Tensor(train_labels)\n",
        "train_input_len = torch.Tensor(train_input_len)\n",
        "dataset = torch.utils.data.TensorDataset(train_padded[0], train_input_len , train_labels)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_labels = torch.Tensor(test_labels)\n",
        "test_input_len = torch.Tensor(test_input_len)\n",
        "dataset = torch.utils.data.TensorDataset(test_padded[0], test_input_len , test_labels)\n",
        "test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgHhce5ZSnph",
        "outputId": "ab7b282b-67b7-46de-9b6a-763a6bcb8e36"
      },
      "source": [
        "#download word2vec\n",
        "!gdown --id 19wlnUlDGtQc0p3XCBKudlGf4pW4C53_d"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19wlnUlDGtQc0p3XCBKudlGf4pW4C53_d\n",
            "To: /content/baomoi.model.bin\n",
            "708MB [00:05, 127MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_iIsOMgTJZT"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import random\n",
        "def read_embedding(word2vec_path):\n",
        "    weights = []\n",
        "    word_to_index = {}\n",
        "    word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
        "\n",
        "    word_to_index['<unk>'] = len(weights)\n",
        "    weights.append([random.uniform(0, 1) for _ in range(400)])\n",
        "    word_to_index['<pad>'] = len(weights)\n",
        "    weights.append([0 for _ in range(400)])\n",
        "\n",
        "    for word in word2vec.wv.vocab:\n",
        "        word_to_index[word] = len(weights)\n",
        "        weights.append(word2vec.get_vector(word))\n",
        "\n",
        "    return word_to_index, torch.tensor(weights, dtype=torch.float32)\n",
        "    \n",
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.shape\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    emb_layer.from_pretrained(torch.FloatTensor(weights_matrix))\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoYmJm5y8Hd5",
        "outputId": "1301b9f1-b371-4643-fb32-84f62bdfa6f8"
      },
      "source": [
        "word_to_index, weights = read_embedding('/content/baomoi.model.bin')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXq4rV3iPi9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a2177a-9c08-42d5-ff64-8a637076aaf7"
      },
      "source": [
        "weights.size()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([439058, 400])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ayANcERChq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8196c2c5-755c-4a72-c144-3b5244d89bc1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.autograd import Variable \n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.nn.utils.rnn import pad_packed_sequence\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f49d3bada30>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PO_r-XESss_"
      },
      "source": [
        "class MyLSTM(nn.Module):\n",
        "    def __init__(self, num_classes,  hidden_size, num_layers,weights_matrix):\n",
        "        super(MyLSTM, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = 128\n",
        "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix,True)\n",
        "\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_size,\n",
        "                            num_layers = num_layers, bidirectional = False, batch_first = True)\n",
        "        self.fc_1 = nn.Linear(self.hidden_size, 64)\n",
        "        self.fc_2 = nn.Linear(64,num_classes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "    \n",
        "    def forward(self,x,x_length):\n",
        "        batch_size = x.shape[0]\n",
        "        # len = torch.sum(x != 0, axis=1) -1\n",
        "        x = self.embedding(x)\n",
        "        x =pack_padded_sequence(x, x_length.tolist(), batch_first=True,enforce_sorted=False)\n",
        "        x, (h_n, c_n)  = self.lstm(x)\n",
        "        # x,_  = pad_packed_sequence(x, batch_first=True)\n",
        "        # x = x[torch.arange(x.shape[0]),len,:]\n",
        "        x = h_n[-1].view(batch_size,-1)\n",
        "        x = self.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "        return x"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxO1m_IRZlSp"
      },
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, test_loader):\n",
        "    # model.load_state_dict(torch.load('/content/drive/MyDrive/sentiment_analysis/folder{}_baomoiEmb.pth'.format(folder_id)))\n",
        "    print('hi!!!')\n",
        "    highest_acc = 0.7\n",
        "    for epoch in range(1,n_epochs+1):\n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for inputs, inputs_len , labels in train_loader:\n",
        "            inputs, inputs_len = inputs.type(torch.LongTensor), inputs_len.type(torch.LongTensor)\n",
        "            labels = labels.type(torch.LongTensor)\n",
        "            output = model(inputs.to(device),inputs_len.to(device))\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.cross_entropy(output, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train +=loss.item()\n",
        "            \n",
        "        correct = 0\n",
        "        # break\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                input, input_len, label = data\n",
        "                input, input_len = input.type(torch.LongTensor), input_len.type(torch.LongTensor)\n",
        "                label = label.type(torch.LongTensor)\n",
        "                output = model(input.to(device),input_len.to(device))\n",
        "                predicted = torch.argmax(output,1)\n",
        "                c = (predicted == label.to(device))#.squeeze()\n",
        "                correct += c.sum()\n",
        "\n",
        "        if epoch == 1 or epoch % 1 == 0:\n",
        "            print('Epoch {}, Training loss {}, Val accuracy {}'.format(\n",
        "                epoch,\n",
        "                loss_train / len(train_loader),\n",
        "                correct / len(test_labels)))\n",
        "            \n",
        "        if correct/len(test_labels) > highest_acc:\n",
        "            highest_acc = correct/len(test_labels)\n",
        "            print('new highest accuracy: ', highest_acc)\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/sentiment_analysis/folder{}_baomoiEmb.pth\".format(folder_id))\n",
        "    print(highest_acc)\n",
        "\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uZHvnHxpKTK",
        "outputId": "352760f0-54aa-4afa-df4e-4fb2a7c91d5b"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Picking GPU if available or else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "device = get_default_device()\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=False)\n",
        "class DevicedataLoader():\n",
        "    def __init__(self,dl,device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "print(device)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVycw6Mzdwa5"
      },
      "source": [
        "learning_rate = 1e-4\n",
        "\n",
        "input_size = EMBEDDING_DIM\n",
        "hidden_size = EMBEDDING_DIM\n",
        "\n",
        "num_layers = 5 #number of stacked lstm layers\n",
        "\n",
        "num_classes = 3 #number of output classes"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zwUwVW6ZlWa"
      },
      "source": [
        "lstm_model = MyLSTM(num_classes, hidden_size, num_layers,weights)\n",
        "lstm_model.to(device)\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egRzxXiCZwoR"
      },
      "source": [
        "train_loader = DevicedataLoader(train_loader,device)\n",
        "test_loader = DevicedataLoader(test_loader,device)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyEMrzJkdhi6"
      },
      "source": [
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = lstm_model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        "    test_loader = test_loader\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym61_DCgWfSn"
      },
      "source": [
        "# baomoiEmb\n",
        "- folder 1: 0.7319\n",
        "- folder 2: 0.7621\n",
        "- folder 3: 0.7891\n",
        "- folder 4: 0.8024\n",
        "- folder 5: 0.7894"
      ]
    }
  ]
}